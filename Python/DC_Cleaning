# Common Problems
#   Inconsistent column names ; missing data ; outliers ; duplicate rows ; untidy ; 
#   need to process columns ; colum types signal unexpected values

import pandas as pd
df = pd.read_csv('filename.csv')
df.head()  # methods
df.tail()  
df.info()
df.columns # attributes
df.shape 

df.continent.value_counts(dropna=False)         # same as df['continent'].value_counts(dropna=False)
df.country.value_counts(dropna=False).head()    # returns sorted list ...good for identifing duplicates
df.fertility.value_counts(dropna=False).head()  # can see missing as a value for 5 obs. .. mixed type
df.population.value_counts(dropna=False).head() # can see NaN occurs 42 times

df.describe()        # summary stats, 8 values (count, mean, std, 5-num summary)
print(df['Site Fill'].value_counts(dropna=False))
print(df['Site Fill'].describe())


# histograms
import matplotlib.pyplot as plt
df.population.plot('hist')
plt.show()
df[df.population > 1000000000]  (show all countries with pop greater than billion people 
df.boxplot(column='population', by'continent')

univ-cont:  boxplot-violin-plot, density-histogram
uni-cat:   barchart
bi-cont-cont:  scatter
bi-cont-cat:  boxplot, by
bi-cat-cat:  


# Import matplotlib.pyplot
import matplotlib.pyplot as plt

# Plot the histogram
df['Existing Zoning Sqft'].plot(kind='hist', rot=70, logx=True, logy=True)
df.boxplot(column='initial_cost', by='Borough', rot=90)
# Display the histogram
plt.show()


df.plot(kind='scatter', x='initial_cost', y='total_est_fee', rot=70)



########## Tidy Data   Hadly Wickham, 2014  ... columns=variables, rows=individuals (not fully wide, but not stacked)
# "Every column is a variable, and every row is an observation"

## When columns contain values instead of variables, use pd.melt()
pd.melt(frame=df, id_vars='name' , value_vars=['treatment a','treatment b']
                                   var_name='treatment, value_name='result')         # moves value_vars from wide to long

## When Columns contain variables that should be wide, use pd.pivot
weather_tidy = weather.pivot(index='date', columns='element', values='value')     # index is the id var, columns are the vars to widen

# pivot() method will fail if there are duplicate ids .... in that case, use pivot_table
weather2_tidy = weather.pivot_table(index='date', columns='element', values='value', aggfunc=np.mean )

airquality_pivot = airquality_melt.pivot_table(index=['Month','Day'], columns='measurement', values='reading')

### To fix a hierarchial index, just reset it
print(airquality_pivot.index)                                # Print the index of airquality_pivot
airquality_pivot_reset = airquality_pivot.reset_index()      # Reset the index of airquality_pivot: airquality_pivot_reset
print(airquality_pivot_reset.index                           # Print the new index of airquality_pivot_reset
print(airquality_pivot_reset.head())                         # Print the head of airquality_pivot_reset


### Sometimes variables are convoluted in columns ...eg Male0-14 Male15-24 ... ideally want separate sex and age columns
tb_melt = pd.melt(frame=tb , id_vars=['country','year'])           #melt everything down into a stack
tb_melt['sex'] = tb_melt.variable.str[0]                           # sex is the first character of the word in 'variable'
tb_melt['age_group'] = tb_melt.variable.str[1:]



ebola_melt = pd.melt(ebola, id_vars=['Date', 'Day'], var_name='type_country', value_name='counts')
ebola_melt['str_split'] = ebola_melt.type_country.str.split('_')               # Create the 'str_split' column
ebola_melt['type'] = ebola_melt.str_split.str.get(0)                      # Create the 'type' column
ebola_melt['country'] = ebola_melt.str_split.str.get(1)                 # Create the 'country' column
print(ebola_melt.head())                                                 # Print the head of ebola_melt


########## Combining Data   ##########
# Row-wise (appending ... axis=0 , default)
concat_data = pd.concat([data1, data2])           # note, original indicies will be kept  so concat_dat.loc[0,:] has multiple rows
concat_data = pd.concat([data1, data2] , ignore_index=True)        # resets index label

# Columnwise (joining  ... axis=1)
ebola_tidy = pd.concat([ebola_melt,status_country],axis=1)

### to create very long lists of concatinate objects, use globbing , which will return a list of matches
import glob
csv_files = glob.glob('*.csv')
list_data = []
for filename in csv_files:
    data = pd.read_csv(filename)           # note, to proof, use : peek= pd.read_csv(csv_files[1]) ... peek.head() ,etc
    list_data.append(data)                # list of data frames
pd.concat(list_data)

##### Merging           1:1 , many:1 or 1:many just depend on keys and right/left
pd.merge(left=state_populations, right=state_codes,
         on=None, left_on='state' , right_on='name')          # if common key is named differntly, need to use on=None

# Merge the DataFrames: m2o
m2o = pd.merge(left=site, right=visited,
          on=None, left_on='name' , right_on='site')

##### Converting Data Types (recasting)
df['var'] = df['var'].astype(str)                   # can recast variable itself to a string
df['sex'] = df['sex'].astype('category')            # can be cast as a factor like category  (saves memory if levels<c
df['nums'] = pd.to_numeric(df['nums'], errors='coerce')    # forces conversion, creates NaN for inconvertable

##### String Manipulation   (re package)             
https://docs.python.org/2/howto/regex.html
https://docs.python.org/2/library/re.html#re-syntax
17          $17           $17.00          $17.89      $17.895   
12345678901 $123455678901 
\d*         \$\d*         \$\d*\.\d{2}  \$\d*\.\d{2}  ^\$\d*\.\d{2}$
Good practice ... compile pattern to variable first, then match the variable.

import re
pattern = re.compile('\$\d*\.\d{2}')
result = pattern.match('$17.89')
bool(result)                                 #True

# returing list of matches 
matches = re.findall('pattern', 'string')
matches = re.findall('\d+', 'the recipe calls for 10 strawberries and 1 banana')      # ['10','1']

pattern1 = bool(re.match(pattern='\d{3}-\d{3}-\d{4}', string='123-456-7890'))
pattern2 = bool(re.match(pattern='\$\d{3}\.\d{2}', string='$123.45'))
pattern3 = bool(re.match(pattern='[A-Z]\w*', string='Australia'))

df.apply(np.mean, axis=0)       # will find means of columns
df.apply(np.mean, axis=1)       # will find means of rows


import re
from numpy import NaN
pattern = re.compile('^\$\d*\.\d{2}$')    # regular expression for monitary values
diff_money.py
--------
def diff_money(row,pattern):
    icost = row['Initial cost']
    tef   = row['Total Est. Fee']
    if bool(pattern.match(icost)) and bool(pattern.match(tef)):
    
        icost = icost.replace('$','')
        tef   = tef.replace('$','')
        
        icost = float(icost)
        tef = float(tef)
        return icost - tef
    else:
        return NaN
----
df_subset['diff'] = df_subset.apply(diff_money, axis=1, pattern-pattern)


def recode_sex(sex_value):
    if sex_value == 'Male':                                 # Return 1 if sex_value is 'Male'
        return 1
    elif sex_value == 'Female':                                # Return 0 if sex_value is 'Female'    
        return 0
    else:
        return np.nan                                         # Return np.nan    

tips['sex_recode'] = tips.sex.apply(recode_sex)               # Apply the function to the sex column

### lambda functions
def my_square(x)                                  df.apply(lambda x: x**2)
  return x**2
  
df.apply(mysquare)


tips['totdollar_replace'] = tips.totdollar.apply(lambda x: x.replace('$', ''))             # replaces $ with ''
tips['totdollar_re']      = tips.totdollar.apply(lambda x: re.findall('\d+\.\d+', x)[0])   # extracts the number without $
print(tips.head())       #   $16.99    16.99       16.99


##### Duplicate Data         
df..drop_duplicates()       # drops any duplicated lines


###### missing data
## dropping missing values
tips_dropped = tips_nan.dropna()

## filling in missing values
tips_nan['sex'] = tips_nan['sex'].fillna('missing')                            # replaces missing with text-string
tips_nan[['total_bill','size']] = tips_nan[['total_bill','size']].fillna(0)    # replaces missing with 0
mean_value = tips_nan.tip.mean()
tips_nan['tip'] = tips_nan['tip'].fillna(mean_value)

##### Assert satemenst / testing with asserts   (if asserts to true, nothing happens , otherwise stops with error
assert google.Close.notnull().all()              # if there are missing values, will give error
google_0 = google.fillna(value=0)
assert google_0.Close.notnull().all()         # doesn't give error

pd.notnull(df)   is synonym to   df.notnull()

assert ebola.notnull().all().all()
assert (ebola >=0).all().all()


########## Putting it all together
import pandas as pd
df = pd.read_csv('mydata.csv')
df.head()
df.info()
df.columns
df.describe()
df.column.value_counts()
df.column.plot('hist')

def cleaning_function(row_data):
  # cleaning steps
  return
df.apply(cleaning_function        )  # colwise
df.apply(cleaning_function, axis=1)  # rowwise
assert (df.column_data > 0).all()    


import matplotlib.pyplot as plt
g1800s.plot(kind='scatter', x='1800', y='1899')
plt.xlabel('Life Expectancy by Country in 1800')
plt.ylabel('Life Expectancy by Country in 1899')
plt.xlim(20, 55)
plt.ylim(20, 55)
plt.show()



def check_null_or_valid(row_data):
    """Function that takes a row of data,
    drops all missing values,
    and checks if all remaining values are greater than or equal to 0
    """
    no_na = row_data.dropna()[1:-1]
    numeric = pd.to_numeric(no_na)
    ge0 = numeric >= 0
    return ge0


assert g1800s.columns[0] == 'Life expectancy'               # Check whether the first column is 'Life expectancy'
assert g1800s.iloc[:, 1:].apply(check_null_or_valid, axis=1).all().all()      # Check whether the values in the row are valid
assert g1800s['Life expectancy'].value_counts()[0] == 1       # Check that there is only one instance of each country









### Metacharacters . & $ * + ? { } [ ] \ | ( )
[] Character Classes .. set of characters on which to match .. note a,b,c == a-c  (metacharacters not active inside classes)
[^x] is the complement set (any character except x)
\  Escape character ... \[ will match [  ..\\ will match a \
\d ==  [0-9]    \D == [^0-9]    \s == [ \t\n\r\f\v]   \S == [^ \t\n\r\f\v]  \w == [a-zA-Z9-0_]    \W == [^a-zA-Z9-0_]
[\s,.]    will match any whitespace, . and , ... so sequence symbols allowed in CharClasses
.              == [^\n]   ie anything except newline character
re.DOTALL      matches anything , including newline







